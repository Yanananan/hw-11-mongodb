// Dependencies
var express = require("express");
var mongojs = require("mongojs");
// Require request and cheerio. This makes the scraping possible
var request = require("request");//backend version of ajax, gets entire html
var cheerio = require("cheerio");//use jQuery-like syntax
var bcrypt = require('bcryptjs');
var ObjectId = require('mongodb').ObjectID;

// Initialize Express
var app = express();

// Database configuration
var databaseUrl = "food_wine";
var collections = ["articles"];

// index.html in the public folder will over ride the root route
app.use(express.static("public"));

// Hook mongojs configuration to the db variable
var db = mongojs(databaseUrl, collections);
db.on("error", function(error) {
    console.log("Database Error:", error);
});

//you need this to be able to process information sent to a POST route
var bodyParser = require('body-parser');
// parse application/x-www-form-urlencoded
app.use(bodyParser.urlencoded({ extended: true }));
// parse application/json
app.use(bodyParser.json());

var commentArray, storedHash, commentUID;


// Main route (simple Hello World Message)
app.get("/", function(req, res) {
    res.send("Hello world");
});

// Retrieve data from the db
app.get("/all", function(req, res) {
    // Find all results from the articles collection in the db
    db.articles.find().sort({publishDateForSorting:-1}, function(error, found) {
        if (error) {
            console.log(error);
        } else {
            res.json(found);
        }
    });
});

app.get("/article/:_id",function(req,res){
    // Find one article using the UID generated by mongo
    console.log("req.params");
    console.log(req.params);
    db.articles.find(
        {"_id" : ObjectId(req.params["_id"])}, 
        function(error, found) {
            if (error) {
                console.log(error);
            } else {
                res.json(found);
            } 
        }
    );
})


app.get("/scrape", function(req, res) {
    request("https://www.foodandwine.com/news", function(error, response, html) {
        var $ = cheerio.load(html);
        $("article").each(function(i, element) {
            // Data to scrape:
            // title,link,picUrl,
            var title = $(element).children(".media-body").children(".headline").children("a").text();
            // if there were two links inside, there aren't but if there were, and you want the second link then you would do this
            // var title = $(element).children("a").eq(1).text();
            var link = $(element).children(".media-body").children(".headline").children("a").attr("href");
            var picUrl = $(element).children(".media-img").children(".component").attr("data-src");
            if (picUrl.indexOf('https') == -1){
                // sometimes articles do not have an image, in this case, food&wine uses a default image with the internal link "/img/icons/missing-image-4x3.svg".  the full website needs to be prepended for this link to work in my website
                picUrl = "https://www.foodandwine.com"+picUrl;
            }
            db.articles.find({
                // search to see if link already exists in db. if link exists, that means article exists in db already, so it will not be added
                link:link
            }, function(err, found){
                if (err) {
                console.log("encountered error during search...")
                console.log(err);
                } else {
                    if (title && link && (found.length==0)) {
                        // if article is unique and new, there is more to scrape:
                        // author, authorDate(article post date),
                        // articleContent(array of paragraphs from article)
                        request("https://www.foodandwine.com"+link, function(error2, response2, html2) {
                            var $ = cheerio.load(html2);
                            var author = $(".author-name").text();
                            var publishDate = $(".published-date").text();
                            var articleContent = [];
                            $(".padded > p").each(function(j, element2) {
                                if (($(element2).text().trim())!=""){
                                // sometimes paragraph tags contain video links only, which should not be added to articleContent.
                                articleContent.push($(element2).text().trim());

                                // try scraping html instead of text???
                                }
                            })

                            db.articles.insert({
                                title: trimStr(title),
                                link: link,
                                picUrl: picUrl,
                                author: author,
                                publishDateForDisplay: trimStr(publishDate),
                                publishDateForSorting: convertDate(trimStr(publishDate)),//have to convert "September 20, 2018" to "2018-09-20" format for sorting by post date to work
                                articleContent: articleContent,
                                comments:[]
                            },
                            function(err, inserted) {
                                if (err) {
                                console.log("encountered error during insert...")
                                console.log(err);
                                } else {
                                console.log(inserted);
                                }
                            });
                        });
                    }
                }
            })
        });
    });

    // Send a "Scrape Complete" message to the browser
    res.send("Scrape Complete");
});

app.post("/comment/:_id", function(req, res) {
    console.log("req.params");
    console.log(req.params);
    console.log("req.body");
    console.log(req.body);

    bcrypt.genSalt(10, function(err, salt) {
        bcrypt.hash(req.body.userPIN, salt, function(err, p_hash) {
            console.log("p_hash for insert");
            console.log(p_hash);
            db.articles.update(
                { "_id" : ObjectId(req.params["_id"]) },
                { $push: { "comments" : {
                    "userName": req.body.userName,
                    "userPIN": p_hash,
                    "userComment": req.body.userComment,
                    "commentUID": req.body.userName + Date.now()// I can't figure how to create a UID for each comment so this will have to do
                } } },
                function (err, inserted) {
                    console.log("inserted");
                    res.end();
                }
            )
        })
    })
    
    

});

app.post("/delete/:_id", function(req, res) {
    //ideally i can implement a login system, but i don't have enough time atm so a janky password check will have to do
    console.log("req.params");
    console.log(req.params);
    console.log("req.body");
    console.log(req.body);

    db.articles.find(
        {"_id" : ObjectId(req.params["_id"])}, 
        function(error, found) {
            if (error) {
                console.log("error");
                console.log(error);
            } else {
                console.log("found");
                console.log(found);
                commentArray = found[0].comments;
                storedHash = commentArray[req.body.deleteButtonID].userPIN;
                commentUID = commentArray[req.body.deleteButtonID].commentUID;
                console.log("storedHash");
                console.log(storedHash);
            }
            bcrypt.compare(req.body.deleteCommentPIN, storedHash, function(err, result) {
                if (err) {
                    console.log("err");
                    console.log(err);
                } else {
                    if (result){
                        db.articles.update(
                            {"_id" : ObjectId(req.params["_id"]) },
                            { $pull: { comments: {"commentUID":commentUID}}},
                            function (err, deleted) {
                                console.log("deleted");
                                res.end();
                            }
                        )
                    }
                }
                
            })
        }
    );

    
})

// Listen on port 3000
app.listen(3000, function() {
  console.log("App running on port 3000!");
});

var dateArray;
var months = {
  'January' : '01',
  'February' : '02',
  'March' : '03',
  'April' : '04',
  'May' : '05',
  'June' : '06',
  'July' : '07',
  'August' : '08',
  'September' : '09',
  'October' : '10',
  'November' : '11',
  'December' : '12'
}
function convertDate(date){
  //date scraped from article is a string in the format "September 20, 2018"
  //function returns format as 2018-09-20
  dateArray = date.split(" ");
  //year is dateArray[2]
  //month is dateArray[0] but converted using the months object above
  //day is dateArray[1] but with comma removed
  return dateArray[2]+"-"+months[dateArray[0]]+"-"+dateArray[1].substring(0, dateArray[1].length - 1)
}

function trimStr(str){
  //some scraped data contains non-breaking spaces and leading and trailing spaces. this function removes them
  return str.replace('\n','').trim();
}
